---
title: "Hyndman Method"
author: "JJ"
date: "3/7/2021"
output: html_document
---

```{r setup, include=FALSE}

library(pacman)
p_load(stringr,purrr,fabletools,tidyr,dplyr,magrittr,tsibble,feasts,future,tidymodels,xgboost)

path = "~/"

files = list.files(path = path, pattern= "*Global.*.csv", all.files=FALSE,
    full.names=FALSE)

read_files = function(accessor){
  
  file = read.csv(str_glue(path,'/',files[accessor])) %>%
    set_colnames(c('DATE','value')) %>%
    mutate(file_name = gsub(".csv",'',files[accessor]))
  
}

df_monthly = map_dfr(1:length(files),read_files) %>%
   mutate(month = tsibble::yearmonth(as.character(DATE))) %>%
   as_tsibble(key = file_name,index =month) %>%
   fill_gaps(value =0)

# look at null data

```

# extract features

```{r }

features_df = df_monthly %>%
  features(value,feature_set(pkgs = "feasts"))


```

# explore features 

```{r pressure, echo=FALSE}

p_load(DataExplorer)

DataExplorer::plot_density(features_df)

```
# split into training and test 

```{r}

p_load(caret,rsample)

split <- initial_split( features_df, prop = .7,seed =3)

# create test and train
train_df <- training(split)
test_df <- testing(split)


```

# train data and look at all the models over time
```{r}

# create cv dataset

cv_ts = df_monthly %>% filter(file_name %in% (train_df %>% pull(file_name))) %>%
 filter(lubridate::year(DATE) >= 2013) %>% # only choose last 8 years of data
 stretch_tsibble(.init = 48, .step = 1) %>%
  fill_gaps(value = 0) 

# run models for cross validation

plan(multisession, gc = TRUE,workers = 14)

df_fable = 
  cv_ts %>% 
      model(snaive = fable::SNAIVE(value ~ lag(lag=12)),
        naive = fable::NAIVE(value),
        arima = fable::ARIMA(value),
        theta = fable::THETA(value),
        eta =    fable::ETS(value)) %>%
  forecast(h = "1 month")

future:::ClusterRegistry("stop")

```

# get the best model and train a xgboost model against it
```{r}

best_model = df_fable %>%
  fabletools::accuracy(df_monthly) %>%
  group_by(file_name) %>%
  filter(MASE == min(MASE,na.rm = TRUE)) 

item_recipe <- training(split) %>% 
  left_join(best_model %>% select(file_name,.model), by = c("file_name" = "file_name")) %>%
  recipe(.model ~.) %>%
  step_rm(file_name) %>%
  step_naomit(all_predictors()) %>%
  prep()

item_testing <- item_recipe %>%
  bake(testing(split))

item_training <- juice(item_recipe)

boost_model = boost_tree(mode = "classification",trees = 5000,learn_rate = 0.001) %>%
  set_engine("xgboost") %>%
  fit(.model ~., data = item_training)

```
# predict weights on test set and see performance

```{r}


weights_df <- boost_model %>%   
  predict(item_testing, type = "prob")

#append the data
model_weights = test_df %>%
  select(file_name) %>%
  bind_cols(weights_df)

# get the predictions for 2020 for test df

cv_ts_test = df_monthly %>% filter(file_name %in% (test_df %>% pull(file_name))) %>%
 filter(lubridate::year(DATE) >= 2013) %>% # only choose last 8 years of data
 stretch_tsibble(.init = 48, .step = 1) %>%
  fill_gaps(value = 0) %>% filter(.id > 36)

# run models for cross validation

plan(multisession, gc = TRUE,workers = 14)

df_fable_test = 
  cv_ts_test %>% 
      model(snaive = fable::SNAIVE(value ~ lag(lag=12)),
        naive = fable::NAIVE(value),
        arima = fable::ARIMA(value),
        theta = fable::THETA(value),
        eta =    fable::ETS(value)) %>%
  forecast(h = "1 month")

future:::ClusterRegistry("stop")

# apply the weights to the last 12 months
predictions_test = df_fable_test %>% as_tibble()%>%
  filter(lubridate::year(month) == 2020 ) %>%
  select(-c(.id,value)) %>%
  pivot_wider(id_cols = c(file_name,month),names_from = .model,values_from = .mean) %>%
  inner_join(model_weights, by =c("file_name" = "file_name")) %>%
  mutate(naive_pred = naive * .pred_naive,
         arima_pred = arima * .pred_arima,
         theta_pred = theta * .pred_theta,
         ets_pred = eta * .pred_eta) %>%
  mutate(weighted_ensemble = naive_pred + theta_pred + ets_pred + arima_pred) %>%
  select(-c(contains('.pred'),contains('_pred')))%>%
  pivot_longer(cols = !c(file_name,month),values_to = 'predictions') %>%
  inner_join(df_monthly, by =c("file_name" = "file_name","month" = "month"))%>%
  group_by(file_name,name)%>%
  yardstick::mase(value,predictions) %>%
  group_by(file_name) %>%
  filter(.estimate == min(.estimate))
  



```

